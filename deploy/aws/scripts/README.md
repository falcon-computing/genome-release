# Submitting Benchmarking Jobs to Falcon Genomics Image on AWS

## Pre-requisites
To perform the performance test in the AWS instance, the following need to be in place:

- In AWS, folder /genome/ with some key data should be mounted.
- Configure aws such that messages can be sent out.

- Storage Device should be defined in /local/ with two sub-folders : fastq/ and ref/
  
- /local/ref/ can be populated from the folder /genome/ref/
    ```
    cp /genome/ref/human_g1k_v37.* . & 
    cp /genome/ref/*vcf*  . & 
    ```
- /local/fastq/ can be populated using data posted /genome/fastq/ 
  Currently, performance test are done using cell lines NA12878 (NA12878-Garvan, NA12878-I33 and NA12878-I47)
  obtained from public domain.  A special set of data from Intel can be obtained in AWS:
    ```
    aws s3 --no-sign-request cp s3://fcs-genome-data/fastq/intel/ . --recursive --exclude "*" --include "H*gz"
    ```
 Â If other FASTQ files are used, make sure the paired-end FASTQ filenames are in the format:  fname_1.fastq.gz and fname_2.fastq.gz
  
- Falcon Executables must be located at: /usr/local/falcon 

- Get the performance scripts:
     ```
     aws s3 --no-sign-request cp s3://fcs-genome-data/fastq/mock/ . --recursive --exclude "*" --include "*sh"
     ```
Three BASH scripts are copied: benchmark_merge.sh, globals.sh, and runbenchmark.sh .

## Check if Executables and Input Files are in place: 
     [centos@ip-123-45-67-890 /local ]$ ./globals.sh
     Check if fcs-exome exists:
     /usr/local/falcon/bin/fcs-genome OK

     Verify License PATH:
     /usr/local/falcon/license.lic OK

     Check BWA_BIN and GATK in FCS:
     /usr/local/falcon/tools/bin/bwa-bin OK
     /usr/local/falcon/tools/package/GenomeAnalysisTK.jar OK

     Checking Global Variables

     Files

     /local/ref/human_g1k_v37.fasta OK
     /local/ref/dbsnp_138.b37.vcf OK
     /local/ref/1000G_phase1.indels.b37.vcf OK
     /local/ref/Mills_and_1000G_gold_standard.indels.b37.vcf OK
     
## Run the Performance Test

The BASH script benchmark_merge.sh is used for the case where a sample with a given ID has several 
paired-end of FASTQ files sequenced in different flowcells or lanes. A small dataset posted 
in AWS is available for testing purposes:

    [centos@ip-123-45-67-890 /fastq ]$ aws s3 --no-sign-request cp s3://fcs-genome-data/fastq/wgs/small/ . --recursive --exclude "*" --include "NA12878*gz"
    
Three pairs of FASTQ files for NA12878 with 100000 paired reads each are in the small set:
    
    [centos@ip-123-45-67-890 /fastq ]$ ls -1 NA*gz
     NA12878-Garvan_small_1.fastq.gz
     NA12878-Garvan_small_2.fastq.gz
     NA12878-I33_small_1.fastq.gz
     NA12878-I33_small_2.fastq.gz
     NA12878-I47_small_1.fastq.gz
     NA12878-I47_small_2.fastq.gz

Submitting the job:

    [centos@ip-123-45-67-890 /local ]$ nohup ./benchmark_merge.sh m4.10x aws NA12878 /genome/Logs/m4.10x/ & 
     
This script looks for the FASTQ files in the /local/fastq folder, align each pair using bwa-bin, and post the outputs
in the folder /local/NA12878/. Subsequently, all the bwa outputs are merged, mark duplicates is performed, and one single
BAM file is generated, which is the input for BQSR. THe base quality score recalibrated BAM file generated by BQSR is then 
used to generate the VCF file using HaplotypeCaller method. 

In each step, log files are posted in /local/NA12878. Once the script completes its tasks, a message is sent out
with a brief summary of the results. The logs are compressed and sent to /genome/Logs/YourInstance/ for records.

The other script runbenchmark.sh follows a similar procedure. But this time, it processes different samples and 
generates results separately. The command is executed as follows:

    [centos@ip-123-45-67-890 /local ]$ nohup ./runbenchmark.sh  m4.10x aws /genome/Logs/m4.10x/ 0

In the example above, the log file is posted at /genome/Logs/m4.10x/  


















